The following repository provides all needed information for the support of a Greek model in spaCy that uses as Part of Speech tags classes with morphological features. The tag map can be found in [this](https://github.com/explosion/spaCy/blob/master/spacy/lang/el/tag_map.py) page. The dataset that was used is a source of news from a newspaper called “Makedonia” and is a part of the clarin project. The dataset in under the CC – BY – NC – SA licence.
Additional work has been done for the support of Named Entity Recognition in the Greek model. The same annotated source was used for the support of 4 types of named entities (person, organization, location, facility). The annotated dataset with named entities is licenced under the CC – BY – NC – SA licence.
For the creation of the model the train and dev data is provided in proper json format. However, to recreate the dataset from source for use, a number of steps has to be followed.
###Steps
* Step 1: Download and extract the dataset from [this](https://keg.clarin.gr/resources/browse/modern-greek-texts-corpus-makedonia-newspaper-annotated-by-the-ilsp-lemmatizer/02a9ea6227fc11e6a7b7aa3fc0687644d756918b84cd4f6a88cf2b2f8c0cf3c9/) link. Extract the sentences from the dataset using parsing_sentences.py. The sentences will be saved in json objects in sentences.json. Also, extract their pos tags using parsing_tags.py. The tags.json will contain the part of speech tag for all tokens matching the index of the record from sentences.json.
* Step 2: Download and extract the dataset from [this](https://keg.clarin.gr/resources/browse/modern-greek-texts-corpus-makedonia-newspaper-annotated-by-the-grne-tagger/76777cae4c8811e89c6caa3fc6ebde2ce44e9fd17cce43d8ab298aae0c7058fe/) link. Create the entity list using making_entity_list.py. Edit the entity list with edit_entity_list.py. The list is used to extract the annotated entities from the sentences with parsing_entities.py.
* Step 3: Convert the entities to bilou format with convert_to_biluo.py.
* Step 4: Convert files in proper json format and split the dataset in train and dev data with convert_to_json_format_and_split_to_train_dev.py
It must be noted that the extracted directories from the upper sources should be located in the same path. Also, configuration has to be done in the init file of lang/el, so the proper tag_map is used.
The model has been trained using as pretrained vectors the Greek, FastText, Common Crawl vectors from [this](https://fasttext.cc/docs/en/crawl-vectors.html) link. As pipelines the POS Tagger and the Entity Recognizer are provided.